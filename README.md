# ğŸï¸ MotoTrack - IdentificaÃ§Ã£o AutomÃ¡tica de Motos via VisÃ£o Computacional

Este notebook implementa um protÃ³tipo de **VisÃ£o Computacional** utilizando **Transfer Learning** com o modelo **MobileNet** prÃ©-treinado.

---

## ğŸ¯ Objetivos

- âœ… Utilizar o modelo **MobileNet** para identificaÃ§Ã£o automÃ¡tica de motos.
- âœ… Aplicar em imagens capturadas no contexto do pÃ¡tio da **Mottu**.
- âœ… Demonstrar a aplicaÃ§Ã£o prÃ¡tica da **VisÃ£o Computacional** para melhorar a **gestÃ£o de frotas**.

---

## â“ O que Ã© Transfer Learning?

**Transfer Learning** consiste em reutilizar modelos prÃ©-treinados para resolver novos problemas.

### â¡ï¸ Vantagens:

- âœ… Poucos dados necessÃ¡rios.
- âœ… Menor tempo de treinamento.
- âœ… Alta eficiÃªncia.

Neste projeto, usamos o **MobileNet** prÃ©-treinado no **ImageNet**, que jÃ¡ reconhece milhares de objetos, incluindo motos.

---

## ğŸ› ï¸ Frameworks e Ferramentas Utilizadas

### ğŸ”§ TensorFlow/Keras

- ğŸ’ª Uma das bibliotecas mais robustas para **Deep Learning** e **VisÃ£o Computacional**.
- ğŸš€ Permite fÃ¡cil utilizaÃ§Ã£o de modelos prÃ©-treinados como o **MobileNet**.
- â˜ï¸ IntegraÃ§Ã£o ideal com ambientes como o **Google Colab**.

### ğŸ”§ MobileNet

- âš¡ Leve: ideal para ambientes com recursos computacionais limitados.
- ğŸ¯ Eficaz: mantÃ©m alta acurÃ¡cia em tarefas de classificaÃ§Ã£o de imagens, mesmo com arquitetura compacta.

**Contexto:**

O **MobileNet** Ã© ideal para aplicaÃ§Ãµes embarcadas e mÃ³veis, como o **monitoramento inteligente de pÃ¡tios**, pois:

- ğŸï¸ Exige menos processamento.
- âš¡ Executa rapidamente.
- ğŸ”— Pode ser facilmente integrado a sistemas de mapeamento e gestÃ£o de frotas, como no caso da **Mottu**.

### ğŸ”§ Matplotlib e NumPy

- ğŸ“Š **Matplotlib**: exibiÃ§Ã£o grÃ¡fica clara e interpretÃ¡vel dos resultados.
- ğŸ”¢ **NumPy**: suporte a operaÃ§Ãµes matriciais e manipulaÃ§Ã£o eficiente de arrays de imagens.

---

## ğŸ“ Como Usar este Notebook

### âœ… Passo 1: Baixe o notebook

- ğŸ”— Acesse este repositÃ³rio.
- ğŸ“¥ FaÃ§a o download do arquivo `.ipynb` deste notebook.

ğŸ’¡ **Dica:** clique em `Code` â†’ `Download ZIP` ou baixe apenas o notebook desejado.

---

### âœ… Passo 2: Importe para o Google Drive

- ğŸ“‚ Acesse o [Google Drive](https://drive.google.com).
- ğŸ—‚ï¸ Crie uma pasta (opcional, recomendado para organizaÃ§Ã£o).
- ğŸ“¤ FaÃ§a o upload do notebook `.ipynb` para o seu Google Drive.

---

### âœ… Passo 3: Abra no Google Colab

- ğŸ–±ï¸ No Google Drive, clique com o botÃ£o direito no notebook.
- â¡ï¸ Selecione **"Abrir com"** â†’ **"Google Colab"**.
- âœ… O notebook serÃ¡ carregado, pronto para execuÃ§Ã£o.

---

## ğŸ› ï¸ Passos principais dentro do notebook

### ğŸ“¦ InstalaÃ§Ã£o das dependÃªncias

```bash
!pip install tensorflow matplotlib numpy
```

---

### ğŸ“¥ ImportaÃ§Ã£o das bibliotecas

```python
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
```

---

### âš™ï¸ Carregamento do modelo MobileNet

```python
model = MobileNet(weights='imagenet')
print("âœ… Modelo MobileNet carregado com sucesso!")
```

---

### ğŸ§© DefiniÃ§Ã£o da funÃ§Ã£o de classificaÃ§Ã£o

```python
def classify_image(img_path, model):
    # Carrega e exibe forma original
    img = image.load_img(img_path, target_size=(224, 224))
    print(f"Shape da imagem original: {np.array(img).shape}")

    # Converte para array e prÃ©-processa
    x = image.img_to_array(img)
    print(f"Shape apÃ³s conversÃ£o em array: {x.shape}")

    x = np.expand_dims(x, axis=0)
    print(f"Shape apÃ³s expansÃ£o: {x.shape}")

    x = preprocess_input(x)

    # Tempo de execuÃ§Ã£o
    import time
    start = time.time()
    preds = model.predict(x)
    end = time.time()
    print(f"Tempo de processamento: {end - start:.2f} segundos")

    # Decodifica prediÃ§Ãµes
    decoded_preds = decode_predictions(preds, top=5)[0]

    # Exibe imagem com Top-1 prediÃ§Ã£o
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Top-1: {decoded_preds[0][1]} ({decoded_preds[0][2]*100:.2f}%)")
    plt.show()

    # Exibe todas as Top-5 prediÃ§Ãµes
    print(f"ClassificaÃ§Ã£o para {img_path}:")
    for i, (imagenet_id, label, score) in enumerate(decoded_preds):
        print(f"{i+1}. {label}: {score * 100:.2f}%")
```

---

### ğŸ“‚ Criando estrutura de diretÃ³rios

```python
import os
os.makedirs('data/motos', exist_ok=True)
```

---

### ğŸ“· Download de imagens de exemplo

```bash
!wget https://www.motoo.com.br/fotos/2022/10/960_720/mottu-e-moto-eletrica_01102022_50798_960_720.jpg -O data/motos/moto1.jpg
```

---

### ğŸ“ Lista de imagens para teste

```python
test_images = ['data/motos/moto1.jpg']
```

---

### ğŸš€ ClassificaÃ§Ã£o em lote

```python
for img_path in test_images:
    classify_image(img_path, model)
    print('-' * 50)
```

---

## âœ… Resultados esperados

- âœ… IdentificaÃ§Ã£o correta de imagens de motos como **"motorcycle"**.
- âœ… ExibiÃ§Ã£o grÃ¡fica das imagens com a **Top-1 prediÃ§Ã£o**.
- âœ… ApresentaÃ§Ã£o textual das **5 prediÃ§Ãµes mais provÃ¡veis**.
- âœ… Tempo mÃ©dio de execuÃ§Ã£o: inferior a **1 segundo**.

---

## ğŸ§ DiscussÃ£o dos Resultados

### âœ… Pontos positivos:

- âš¡ RÃ¡pido e eficiente.
- ğŸ¯ Classifica bem motos.

### â— LimitaÃ§Ãµes:

- ğŸš« NÃ£o identifica a posiÃ§Ã£o exata da moto (**sem bounding boxes**).
- ğŸ”„ PossÃ­vel confusÃ£o com classes como **"bicycle"**.

### ğŸ”® Melhorias futuras:

- ğŸ› ï¸ Utilizar detecÃ§Ã£o com **YOLOv8**.
- ğŸ–¥ï¸ Criar interface interativa com **Streamlit**.
- ğŸ“¡ Integrar sensores **IoT** para mapeamento em tempo real.

---

## âœ… ConclusÃ£o

O **MotoTrack** demonstrou com sucesso a aplicaÃ§Ã£o de **Transfer Learning** com **MobileNet** para a **identificaÃ§Ã£o automÃ¡tica de motos**.

### ğŸ”œ PrÃ³ximos passos:

- â• Adicionar detecÃ§Ã£o com **bounding boxes**.
- â• Implementar interface interativa.
- â• Integrar sensores **IoT**.

---

## ğŸš¦ Resumindo

âœ… **Baixe** â†’ âœ… **Importe** â†’ âœ… **Abra** â†’ âœ… **Execute!**

